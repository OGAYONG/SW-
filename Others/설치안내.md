

# Upbit API 사용법

# 1. 아나콘다 설치

-- 파이썬이미 있으면 지우고 설치하는게 좋음.

### * 아나콘다 사이트 : https://www.anaconda.com/products/individual

1. 다운로드
2. ![img](https://media.vlpt.us/images/gillog/post/d3c543e5-55e2-4af3-8e94-180ff9ea3649/image.png)

요것만 유의하고 나머진 걍 패스

3. 설치 완료 후, 윈도우버튼 누르고 - Anaconda prompt  를 켠다.

4. python 이라고 치고, 내용 확인한다ㅡ.

   ![img](https://media.vlpt.us/images/gillog/post/69687d68-ce69-4333-9609-0780bc6e2d8d/image.png)



# 2. PyCharm 설치

설치 url : https://www.jetbrains.com/pycharm/

1. 다운로드 (community 버전)

2. 밑에 내용만 체크 해주고 쭉 설치하면됨

   ![img](https://media.vlpt.us/images/gillog/post/94cfb580-f751-4e0b-9e62-9bfc4f7ff5a4/image.png)

3. pycharm 을 켜고, ![img](https://media.vlpt.us/images/gillog/post/39447980-b381-4700-a1a7-0e946715f460/image.png)

4. new project 생성

5. 생성 중간에

   ![img](https://media.vlpt.us/images/gillog/post/f17cb435-5e91-4e87-afb2-11c5f0b96a94/image.png)

중간에 Base Interpreter 부분을 python.exe로 바꿔줘야함 (아래와 같이)

![img](https://media.vlpt.us/images/gillog/post/e62512ba-1f41-4f29-a04b-6bd7c3f9ff1a/image.png)

6. 그러고 프로젝트 우클릭하고 New -> Python File	 하고 하나 생성해보자.



## Azure Data Factory


* Pipeline은 프로세스 Ochestration을,   ++ 데이터 기반 워크 플로우 (워크플로). 작업단위를 수행하는 작업의 논리적 그룹.

* Data Flows는 Spark를 이용해 데이터 변형 작업을 수행합니다. (데이터 플로)
  Pipeline과 data fllows 차이



* 생성되는 파일이 뭔지? (sink할 떄 생기는)



* notebook (data bricks) 쓰거나 print 찍기



* 파워쿼리는 왜 따로있는지, 쿼리로서의 장점이 뭐가 있는지.

* sink에서 느낌표 에러 표시가 뜨는게 뭘 의미 하는지? 주황색 에러

* log 확인 해 보기  -- coll sid data type을 string으로 바꿔주면 해결.

  

* pipeline에서 탬플릿 확인해보기



* 1주일치를 올려 1달 테스트로 비용 산출할 예정



* sink를 파일 말고 table로 해보던가. 아님 안해보던가.
* Cannot convert to number: number would be truncated요게 뭔지
